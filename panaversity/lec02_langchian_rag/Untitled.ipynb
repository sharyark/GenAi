{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea06420f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "index_name = 'rag-project'\n",
    "# Initialize Pinecone client\n",
    "pc = Pinecone(api_key=\"pcsk_6vw9g4_PQEdxuHkGJ3xhM8Pc8f1wHUPkUB12tksj931BeCQdkoawHT2N8o3hZAZ5SXMG65\")\n",
    "\n",
    "# Create an index\n",
    "# pc.create_index(\n",
    "#     name=index_name,\n",
    "#     dimension=768,\n",
    "#     metric=\"cosine\",\n",
    "#     spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "# )\n",
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# load_dotenv()\n",
    "# PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "# PINECONE_ENVIRONMENT = os.getenv(\"PINECONE_ENVIRONMENT\")\n",
    "# GOOGLE_GEMINI_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "# print(GOOGLE_GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e420b260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the index\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d7d79d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIzaSyAb2JrxBqVZgoG_5oQF7iRZ7jOq9nItwMk\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "import os\n",
    "print(os.getenv(\"GOOGLE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e976059e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
    "vector = embeddings.embed_query(\"hello, world!\")\n",
    "len(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ac5f81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load documents\n",
    "loader = TextLoader(\"./document.txt\")  # Replace with your file\n",
    "documents = loader.load()\n",
    "\n",
    "# Split documents into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3295f277",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:37<00:00,  1.86s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Create embeddings and upload to Pinecone\n",
    "for i, doc in enumerate(tqdm(docs)):\n",
    "    vector = embeddings.embed_query(doc.page_content)\n",
    "    \n",
    "    # Metadata should only contain allowed types (strings, numbers, booleans, or lists of strings)\n",
    "    metadata = {\n",
    "        \"source\": \"document1.txt\",\n",
    "        \"author\": \"Sheryar\",\n",
    "        \"text\": doc.page_content  # Store the document text as a string\n",
    "    }\n",
    "    \n",
    "    # Upsert with (id, vector, metadata)\n",
    "    index.upsert([(f\"doc_{i}\", vector, metadata)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2db84f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sharyar/Desktop/Aritificial_Intelligence/genai/lib/python3.12/site-packages/langchain_community/vectorstores/pinecone.py:68: UserWarning: Passing in `embedding` as a Callable is deprecated. Please pass in an Embeddings object instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "# Create a retriever using the correct Pinecone class initialization\n",
    "retriever = Pinecone(\n",
    "    index,  # Pinecone index object\n",
    "    embeddings.embed_query,  # Embedding function\n",
    "    text_key=\"text\"  # The key used to store text in metadata\n",
    ").as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77787f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Initialize the Gemini model correctly\n",
    "gemini_model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",  # Use \"gemini-pro\" or \"gemini-pro-vision\"\n",
    "    google_api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
    "    temperature=0.5\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11b003b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=gemini_model,\n",
    "    chain_type=\"stuff\",  # Other options: \"map_reduce\", \"refine\"\n",
    "    retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cfcc363c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'where AI is use', 'result': 'AI is widely used in various industries, including healthcare, finance, and robotics. It also powers applications like chatbots, sentiment analysis, speech recognition systems, AI-driven trading algorithms, fraud detection, and risk assessment.'}\n"
     ]
    }
   ],
   "source": [
    "query = \"where AI is use\"\n",
    "response = qa_chain.invoke(query)  # Use .invoke() instead of .run()\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121a9693",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
