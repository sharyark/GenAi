{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sharyar/Desktop/Aritificial_Intelligence/genai/lib/python3.12/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sharyar/Desktop/Aritificial_Intelligence/genai/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
    "vector = embeddings.embed_query(\"hello, world!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(GoogleGenerativeAIEmbeddings.list_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector[:3]\n",
    "len(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to Pinecone index: rag-project\n"
     ]
    }
   ],
   "source": [
    "import pinecone\n",
    "\n",
    "# Initialize Pinecone with the new approach\n",
    "pc = pinecone.Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Create an index (if it doesn't exist)\n",
    "index_name = \"rag-project\"\n",
    "\n",
    "if index_name not in [index.name for index in pc.list_indexes()]:\n",
    "    pc.create_index(name=index_name, dimension=768, metric=\"cosine\")\n",
    "\n",
    "# Get the index for further operations\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "print(f\"Successfully connected to Pinecone index: {index_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5058/1411670716.py:4: LangChainDeprecationWarning: The class `Pinecone` was deprecated in LangChain 0.0.18 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-pinecone package and should be used instead. To use it run `pip install -U :class:`~langchain-pinecone` and import as `from :class:`~langchain_pinecone import Pinecone``.\n",
      "  retriever = Pinecone(\n",
      "/home/sharyar/Desktop/Aritificial_Intelligence/genai/lib/python3.12/site-packages/langchain_community/vectorstores/pinecone.py:68: UserWarning: Passing in `embedding` as a Callable is deprecated. Please pass in an Embeddings object instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "# Create a retriever using the correct Pinecone class initialization\n",
    "retriever = Pinecone(\n",
    "    index,  # Pinecone index object\n",
    "    embeddings.embed_query,  # Embedding function\n",
    "    text_key=\"text\"  # The key used to store text in metadata\n",
    ").as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'author': 'Sheryar', 'source': 'document1.txt'}, page_content='---\\n\\nTitle: The Impact of AI on Jobs and Automation  \\nContent: AI-driven automation is transforming industries by replacing repetitive tasks. While some jobs are at risk, new opportunities are emerging in AI development and maintenance.\\n\\n---\\n\\nTitle: The Concept of Shannon’s Information Theory  \\nContent: Shannon’s Information Theory laid the foundation for modern digital communication. It introduced key concepts such as entropy, data compression, and error correction.\\n\\n---')]\n"
     ]
    }
   ],
   "source": [
    "query = \"what on Jobs \"\n",
    "results = retriever.invoke(query, k=1)  # 'k' specifies the number of results\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "def answer_to_user(query):\n",
    "    # Step 1: Retrieve relevant document(s)\n",
    "    results = retriever.invoke(query, k=1)\n",
    "\n",
    "    # Extract the retrieved document's text (assuming it's stored under the key \"text\")\n",
    "    retrieved_text = results[0].dict()[\"page_content\"] if results else \"No relevant document found.\"\n",
    "\n",
    "    # Step 2: Initialize the Gemini model\n",
    "    gemini_model = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.0-flash\",  # You can also use \"gemini-pro\"\n",
    "        google_api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
    "        temperature=0.5\n",
    "    )\n",
    "\n",
    "    # Step 3: Construct a prompt for the LLM\n",
    "    prompt = f\"\"\"\n",
    "    You are an AI assistant. Answer the following query using the provided retrieved document.\n",
    "\n",
    "    Query: {query}\n",
    "\n",
    "    Retrieved Document: {retrieved_text}\n",
    "\n",
    "    Based on the above document, generate the best possible answer.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 4: Generate an answer using Gemini LLM\n",
    "    response = gemini_model.invoke(prompt)\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_80111/1462327689.py:9: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  retrieved_text = results[0].dict()[\"page_content\"] if results else \"No relevant document found.\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='AI-driven automation is transforming industries by replacing repetitive tasks. While some jobs are at risk, new opportunities are emerging in AI development and maintenance.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-559e1207-1599-4e68-9c34-37bd1e2efed7-0', usage_metadata={'input_tokens': 145, 'output_tokens': 30, 'total_tokens': 175, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_to_user(\"what is the  Impact of AI on Jobs \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
